%
% Niniejszy plik stanowi przykład formatowania pracy magisterskiej na
% Wydziale MIM UW.  Szkielet użytych poleceń można wykorzystywać do
% woli, np. formatujac wlasna prace.
%
% Zawartosc merytoryczna stanowi oryginalnosiagniecie
% naukowosciowe Marcina Wolinskiego.  Wszelkie prawa zastrzeżone.
%
% Copyright (c) 2001 by Marcin Woliński <M.Wolinski@gust.org.pl>
% Poprawki spowodowane zmianami przepisów - Marcin Szczuka, 1.10.2004
% Poprawki spowodowane zmianami przepisow i ujednolicenie
% - Seweryn Karłowicz, 05.05.2006
% Dodanie wielu autorów i tłumaczenia na angielski - Kuba Pochrybniak, 29.11.2016

% dodaj opcję [licencjacka] dla pracy licencjackiej
% dodaj opcję [en] dla wersji angielskiej (mogą być obie: [licencjacka,en])
\documentclass[licencjacka,en]{pracamgr}

% Dane magistranta:
%\autor{Imię Nazwisko}{231040}

% Dane magistrantów:
\autor{Tomasz Grześkiewicz}{394317}
\autori{Mateusz Kobak}{385760}
\autorii{Iwona Kotlarska}{394380}
\autoriii{Krzysztof Piesiewicz}{385996}
%\autoriv{Autor nr Cztery}{432145}
%\autorv{Autor nr Pięć}{342011}

\title{Dataloading optimisation for deep learning on NVIDIA GPUs}
\titlepl{Optymalizacja wprowadzania danych na karty graficzne NVIDIA}

%\tytulang{An implementation of a difference blabalizer based on the theory of $\sigma$ -- $\rho$ phetors}

%kierunek:
% - matematyka, informacyka, ...
% - Mathematics, Computer Science, ...
\kierunek{Computer Science}

% informatyka - nie okreslamy zakresu (opcja zakomentowana)
% matematyka - zakres moze pozostac nieokreslony,
% a jesli ma byc okreslony dla pracy mgr,
% to przyjmuje jedna z wartosci:
% {metod matematycznych w finansach}
% {metod matematycznych w ubezpieczeniach}
% {matematyki stosowanej}
% {nauczania matematyki}
% Dla pracy licencjackiej mamy natomiast
% mozliwosc wpisania takiej wartosci zakresu:
% {Jednoczesnych Studiow Ekonomiczno--Matematycznych}

% \zakres{Tu wpisac, jesli trzeba, jedna z opcji podanych wyzej}

% Praca wykonana pod kierunkiem:
% (podać tytuł/stopień imię i nazwisko opiekuna
% Instytut
% ew. Wydział ew. Uczelnia (jeżeli nie MIM UW))
\opiekun{dr Janusz Jabłonowski\\
  University of Warsaw\\
  Faculty of Mathematics, Informatics and Mechanics\\
  Institute of Informatics
  }

% miesiąc i~rok:
\date{May 2020}

%Podać dziedzinę wg klasyfikacji Socrates-Erasmus:
\dziedzina{
%11.0 Matematyka, Informatyka:\\
%11.1 Matematyka\\
%11.2 Statystyka\\
%11.3 Informatyka\\
% poniższy angielski odpowiednik wzięty stąd: https://www.unica.it/UserFiles/File/Direzioni/Direlai/socrates-erasmus/Erasmus%20Subject%20Area%20Codes.doc
11.3 Informatics, Computer Science
%11.4 Sztuczna inteligencja\\
%11.5 Nauki aktuarialne\\
%11.9 Inne nauki matematyczne i informatyczne
}

%Klasyfikacja tematyczna wedlug AMS (matematyka) lub ACM (informatyka)
\klasyfikacja{D. Software
%TODO dodać kolejne, głębsze
}

% Słowa kluczowe:
\keywords{deep learning, GPU, dataloader}

% Tu jest dobre miejsce na Twoje własne makra i~środowiska:
\newtheorem{defi}{Definition}[section]

% koniec definicji

\begin{document}
\maketitle

%tu idzie streszczenie na strone poczatkowa
\begin{abstract}
In this thesis dataloading process has been described for needs of deep learning. The concept of the process has been deliberated in terms of time consumed by computing machines. There is an overview of a current state of the domain including programming techniques used by Python deep learning frameworks: PyTorch and TensorFlow. The aim of thesis has been finding bottle necks of dataloading for common deep learning tasks and optimise some of them at the internal code level of the frameworks or the usage of the frameworks. The analysis has been limited to PyTorch and TensorFlow cooperating with NVIDIA GPUs. As a result of the analysis, several bottle necks has been identified. Some of them has been optimised at the internal framework level, a few others has been explained how to be optimised adjusting the use of the frameworks.
\end{abstract}

\tableofcontents
%\listoffigures
%\listoftables

\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

For several years the terms \emph{Deep learning} and \emph{Neural networks} have been getting more and more recognisable thanks to the great impact of this technology on a huge variety of business aspects. \emph{Speech recognition}, \emph{interpretation of natural language}, \emph{image classification}, \emph{computer vision} and even \emph{self-driving vehicles} are examples of the use of the deep learning technology. The increasing demand for deep learning solutions has caused the race to maximised the performance of available computing machines. The research and practise have shown that GPUs are best suited for deep learning computation purpose because they are unrivaled in linear algebra computations. There are several manners of increasing the performance and all of them are the interests of research and development teams of information technology industries. Some of the ways are constructing more powerful computing clusters or faster computation units. Others are targeted at software issues (operational systems, programming and algorithmic techniques). \emph{Dataloading} mostly relates to the category which has been mentioned as the last one. Let assume the following definition.

\emph{Dataloading} is the process of copying data from non-volatile storage to GPU memory including processing the data in CPU.

%TODO

\end{document}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: t
%%% coding: latin-2
%%% End:
